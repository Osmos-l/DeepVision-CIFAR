# Dense (Fully Connected Layer)

Une couche **Dense** (ou "Fully Connected") est une couche de neurones dans laquelle **chaque neurone est connectÃ© Ã  toutes les sorties de la couche prÃ©cÃ©dente**.

![alt text](../images/dense.png)

---

## ğŸ¯ Objectif
- Combiner toutes les caractÃ©ristiques extraites en amont (par convolution, pooling, etc.) pour produire une **sortie finale**, souvent une classification.
- Appliquer une transformation linÃ©aire suivie d'une activation non-linÃ©aire.

---

## âš™ï¸ Fonctionnement

Pour un vecteur d'entrÃ©e `x` :
```
y = activation(Wx + b)
```

- `W` : matrice de poids
- `b` : vecteur de biais
- `activation` : fonction non-linÃ©aire (ReLU, Tanh, etc.)
- `y` : sortie du neurone

---

## ğŸ§  Dense vs MLP

> âš ï¸ On confond souvent **Dense** et **MLP**, mais ce nâ€™est pas la mÃªme chose.

| Terme     | Description |
|-----------|-------------|
| **Dense** | Une **seule** couche pleinement connectÃ©e. |
| **MLP**   | Un **empilement de plusieurs couches Dense** avec des fonctions d'activation. C'est un vrai **rÃ©seau de neurones profond**. |

Exemple dâ€™un MLP :
```
Input â†’ Dense â†’ ReLU â†’ Dense â†’ ReLU â†’ Dense â†’ Softmax
```

---

## ğŸ“¦ Exemple concret

Si la couche prÃ©cÃ©dente a produit un vecteur de taille `128`, et quâ€™on veut une sortie de taille `10` (par exemple, pour classifier 10 classes), alors :

- `W` : matrice 10 Ã— 128
- `b` : vecteur de taille 10
- La sortie `y` : vecteur de scores (souvent passÃ© Ã  une Softmax pour obtenir des probabilitÃ©s)

---

## ğŸ“š Ressources

- [CS231n â€“ Fully Connected Layers](http://cs231n.github.io/neural-networks-1/#fc)
- *Deep Learning* â€“ Ian Goodfellow, Yoshua Bengio, Aaron Courville
- *Quand la machine apprend* â€“ Yann LeCun
