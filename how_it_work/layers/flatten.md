# Flatten  
**Couche utilisÃ©e dans les rÃ©seaux de neurones pour transformer une entrÃ©e multi-dimensionnelle en un vecteur 1D.**

![alt text](../images/flatten.png)
---

## ğŸ“Œ Objectif  
- Convertir une reprÃ©sentation spatiale (ex : volume 3D hauteurÃ—largeurÃ—canaux) en un vecteur plat.  
- Permettre la connexion avec des couches pleinement connectÃ©es (MLP) en fin de rÃ©seau.

- La couche flatten **aplatit** les donnÃ©es pour quâ€™elles puissent Ãªtre traitÃ©es par des couches denses classiques.  
- Câ€™est un passage obligÃ© entre la partie convolutionnelle et la partie â€œclassiqueâ€ du rÃ©seau.


---

## âš™ï¸ Comment Ã§a fonctionne ?  
La couche **flatten** prend un tenseur dâ€™entrÃ©e, par exemple une sortie de taille `(batch_size, hauteur, largeur, canaux)`, et le transforme en un vecteur de taille `(batch_size, hauteur Ã— largeur Ã— canaux)`.

---

## ğŸ“‰ Exemple  
Si la sortie dâ€™une couche convolutionnelle est de taille `(1, 4, 4, 8)` (batch de 1 image, 4Ã—4 pixels, 8 canaux), alors aprÃ¨s flatten, la forme sera `(1, 128)` car `4Ã—4Ã—8 = 128`.

---

## ğŸ” Alternatives  
- Certaines architectures utilisent des couches **Global Average Pooling** pour rÃ©duire spatialement les donnÃ©es avant la couche dense, Ã©vitant ainsi le flatten classique.

---

## ğŸ“š Ressources  
- [Stanford CS231n â€“ CNN architectures](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture5.pdf)  
- *Deep Learning* â€“ Ian Goodfellow et al.  
- *Quand la machine apprend* â€“ Yann LeCun  
